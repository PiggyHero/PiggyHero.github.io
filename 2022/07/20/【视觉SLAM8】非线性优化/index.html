<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="在SLAM的数学描述中，我们知道了运动方程和观测方程，但是这两个方程并不是精确成立的，因为包含了噪声的影响，所以要想得到精确的相机和路标点的位姿估计，就需要想办法来应对含噪声的数据。">
<meta property="og:type" content="article">
<meta property="og:title" content="【视觉SLAM8】非线性优化">
<meta property="og:url" content="http://example.com/2022/07/20/%E3%80%90%E8%A7%86%E8%A7%89SLAM8%E3%80%91%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BC%98%E5%8C%96/index.html">
<meta property="og:site_name" content="PiggyHero Wiki">
<meta property="og:description" content="在SLAM的数学描述中，我们知道了运动方程和观测方程，但是这两个方程并不是精确成立的，因为包含了噪声的影响，所以要想得到精确的相机和路标点的位姿估计，就需要想办法来应对含噪声的数据。">
<meta property="og:locale">
<meta property="article:published_time" content="2022-07-19T17:46:44.000Z">
<meta property="article:modified_time" content="2022-07-24T21:53:42.976Z">
<meta property="article:author" content="PiggyHero">
<meta property="article:tag" content="SLAM">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2022/07/20/%E3%80%90%E8%A7%86%E8%A7%89SLAM8%E3%80%91%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BC%98%E5%8C%96/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-Hans'
  };
</script>

  <title>【视觉SLAM8】非线性优化 | PiggyHero Wiki</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>
    <a target="_blank" rel="noopener" href="https://github.com/PiggyHero" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">PiggyHero Wiki</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/07/20/%E3%80%90%E8%A7%86%E8%A7%89SLAM8%E3%80%91%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BC%98%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cutexiaoxin.gif">
      <meta itemprop="name" content="PiggyHero">
      <meta itemprop="description" content="不学习咋整啊！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PiggyHero Wiki">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          【视觉SLAM8】非线性优化
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-07-20 01:46:44" itemprop="dateCreated datePublished" datetime="2022-07-20T01:46:44+08:00">2022-07-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-07-25 05:53:42" itemprop="dateModified" datetime="2022-07-25T05:53:42+08:00">2022-07-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%93%E4%B8%9A%E5%8E%9F%E7%90%86/" itemprop="url" rel="index"><span itemprop="name">专业原理</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>在SLAM的数学描述中，我们知道了运动方程和观测方程，但是这两个方程并不是精确成立的，因为包含了噪声的影响，所以要想得到精确的相机和路标点的位姿估计，就需要想办法来应对含噪声的数据。</p>
<span id="more"></span>
<h2 id="I-状态估计问题"><a href="#I-状态估计问题" class="headerlink" title="I. 状态估计问题"></a>I. 状态估计问题</h2><p>运动和观测方程如下：</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
\boldsymbol{x}_{k}=f\left(\boldsymbol{x}_{k-1}, \boldsymbol{u}_{k}\right)+\boldsymbol{w}_{k} \\
\boldsymbol{z}_{k, j}=h\left(\boldsymbol{y}_{j}, \boldsymbol{x}_{k}\right)+\boldsymbol{v}_{k, j}
\end{array}\right.\tag{1}</script><p>我们知道，$\boldsymbol x_k$ 是相机的位姿，可以用 $T_k\in SE(3)$ 来描述。 而观测方程由针孔模型给定，假设在 $\boldsymbol{x_k}$ 处对路标 $\boldsymbol y_j$ 进行了一次观测，对应到图像上的像素位置 $\boldsymbol {z_{k,j}}$ ，那么观测方程可以表示为：</p>
<script type="math/tex; mode=display">
s \boldsymbol{z}_{k, j}=\boldsymbol{K}\left(\boldsymbol{R}_{k} \boldsymbol{y}_{j}+\boldsymbol{t}_{k}\right)\tag{2}</script><p>在实际中，式（2）并不成立，因为存在噪声项。在运动和观测方程中，我们通常假设两个噪声项 $\boldsymbol {w}_{k}$ 和 $\boldsymbol{v}_{k,j}$ 满足均值为0的高斯分布：</p>
<script type="math/tex; mode=display">
\boldsymbol{w}_{k} \sim \mathcal{N}\left(\mathbf{0}, \boldsymbol{R}_{k}\right), \boldsymbol{v}_{k} \sim \mathcal{N}\left(\mathbf{0}, \boldsymbol{Q}_{k, j}\right)\tag{3}</script><p>其中$\boldsymbol{R}_{k}, \boldsymbol{Q}_{k, j}$ 为协方差矩阵。<strong>因此我们希望从这些含噪声的数据 $\boldsymbol{z}$和 $\boldsymbol u$ 中，可以推断出位姿 $\boldsymbol{x}$ 和路标点 $\boldsymbol{y}$ ，这构成了一个状态估计问题。</strong></p>
<p>下面我们将以批量处理的方法，即考虑全部时刻的状态，来进行状态估计的推导。</p>
<p>考虑从 1 到 N 的所有时刻，并假设有 M 个路标点，定义所有时刻机器人位姿和路标点的坐标为：</p>
<script type="math/tex; mode=display">
\boldsymbol{x}=\left\{\boldsymbol{x}_{1}, \ldots, \boldsymbol{x}_{N}\right\}, \quad \boldsymbol{y}=\left\{\boldsymbol{y}_{1}, \ldots, \boldsymbol{y}_{M}\right\}</script><p>用不带下标的  $\boldsymbol{u}$ 和 $\boldsymbol{z}$ 表示所有时刻的输入和观测数据，所以状态估计的概率表示为：</p>
<script type="math/tex; mode=display">
P(\boldsymbol{x}, \boldsymbol{y} \mid \boldsymbol{z}, \boldsymbol{u})\tag{4}</script><p>也就是在已知输入数据和观测数据 $\boldsymbol{u}$ 和 $\boldsymbol{z}$ 的情况下，求状态 $\boldsymbol x$ 和 $\boldsymbol{y}$ 的条件概率分布。</p>
<blockquote>
<p>这里的输入 $\boldsymbol u$ 在视觉SLAM中，要根据实际情况而定，如果有其他传感器可以测出，我们就可以得到。但是如果没有额外的传感器，那么这里的 $\boldsymbol u$ 实际上也是一个观测量，可以由前端计算出来。</p>
</blockquote>
<p>这里利用<strong>贝叶斯法则</strong>，有：</p>
<script type="math/tex; mode=display">
P(\boldsymbol{x}, \boldsymbol{y} \mid \boldsymbol{z}, \boldsymbol{u})=\frac{P(\boldsymbol{z}, \boldsymbol{u} \mid \boldsymbol{x}, \boldsymbol{y}) P(\boldsymbol{x}, \boldsymbol{y})}{P(\boldsymbol{z}, \boldsymbol{u})}\tag{5}</script><p>这里的状态 $\boldsymbol x$ 和 $\boldsymbol{y}$ 是要估计出来的参数，式（5）左侧称为状态 $\boldsymbol x$ 和 $\boldsymbol{y}$ 的后验概率，我们要求得它们的概率分布是很困难的，但是求出 $\boldsymbol x$ 和 $\boldsymbol{y}$ 取多少时概率最大则是可以的。所以左边最大等于右边最大，右边的分母是取得当前观测值的概率，是一个常数，因此在最大化的过程中可以省略。而 $P(\boldsymbol{x},\boldsymbol{y})$ 表示先验概率，实际上我们可以认为 $\boldsymbol x$ 和 $\boldsymbol{y}$ 是一个确定的值，只不过这个值我们不知道是多大而已，因此可以认为$P(\boldsymbol{x},\boldsymbol{y})=1$ 。</p>
<p>现在只剩下最后一项为 $P(\boldsymbol{z}, \boldsymbol{u} \mid \boldsymbol{x}, \boldsymbol{y})$ ，这一项叫做似然概率，即表示在当前状态  $\boldsymbol x$ 和 $\boldsymbol{y}$  下，观测量 $\boldsymbol{u}$ 和 $\boldsymbol{z}$ 的概率分布，我们已经知道 $\boldsymbol{u}$ 和 $\boldsymbol{z}$ 的具体数值，因此 $P(\boldsymbol{z}, \boldsymbol{u} \mid \boldsymbol{x}, \boldsymbol{y})$ 是关于状态量  $\boldsymbol x$ 和 $\boldsymbol{y}$  的函数，因此有让左边最大等价于让这个函数的取值最大：</p>
<script type="math/tex; mode=display">
(\boldsymbol{x}, \boldsymbol{y})^{*}{ }_{\mathrm{MLE}}=\arg \max P(\boldsymbol{z}, \boldsymbol{u} \mid \boldsymbol{x}, \boldsymbol{y})\tag{6}</script><p>式（6）就是最大似然估计。该式我们可以理解为，<strong>在什么样的状态下，最可能产生现在观测到的数据。</strong></p>
<h2 id="II-最小二乘的引出"><a href="#II-最小二乘的引出" class="headerlink" title="II. 最小二乘的引出"></a>II. 最小二乘的引出</h2><p>在确立了用最大似然估计来估计出相机或机器人的位置和路标点位置后，我们来讨论如何进行最大似然估计呢。</p>
<p><strong>在某一位置，对某一路标点</strong>的观测方程：</p>
<script type="math/tex; mode=display">
\boldsymbol{z}_{k, j}=h\left(\boldsymbol{y}_{j}, \boldsymbol{x}_{k}\right)+\boldsymbol{v}_{k, j}\tag{7}</script><p>这里的噪声项$\boldsymbol{v}_{k} \sim \mathcal{N}\left(\mathbf{0}, \boldsymbol{Q}_{k, j}\right)<br>$为高斯分布，所以观测数据的条件概率为：</p>
<script type="math/tex; mode=display">
P\left(\boldsymbol{z}_{j, k} \mid \boldsymbol{x}_{k}, \boldsymbol{y}_{j}\right)=N\left(h\left(\boldsymbol{y}_{j}, \boldsymbol{x}_{k}\right), \boldsymbol{Q}_{k, j}\right)\tag{8}</script><p>所以观测数据依然符合高斯分布。</p>
<p>我们可以<strong>最小化负对数</strong>来求一个高斯分布的最大似然，现有任意高维高斯分布$\boldsymbol{x} \sim \mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\Sigma})$ ，它的<strong>概率密度函数</strong>展开形式为：</p>
<script type="math/tex; mode=display">
P(\boldsymbol{x})=\frac{1}{\sqrt{(2 \pi)^{N} \operatorname{det}(\boldsymbol{\Sigma})}} \exp \left(-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^{\mathrm{T}} \boldsymbol{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol{\mu})\right)\tag{9}</script><p>对其取负对数，变为：</p>
<script type="math/tex; mode=display">
-\ln (P(\boldsymbol{x}))=\frac{1}{2} \ln \left((2 \pi)^{N} \operatorname{det}(\boldsymbol{\Sigma})\right)+\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^{\mathrm{T}} \boldsymbol{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol{\mu})\tag{10}</script><p>因为对数函数是单调递增的，所以<strong>对原函数求最大化相当于对负对数求最小化</strong>。第一项与 $\boldsymbol x$ 无关，可以略去。<strong>于是只要最小化右侧的二次型项，就得到了对状态的最大似然估计</strong>，代入SLAM的观测模型，相当于求：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\left(\boldsymbol{x}_{k}, \boldsymbol{y}_{j}\right)^{*} &=\arg \max \mathcal{N}\left(h\left(\boldsymbol{y}_{j}, \boldsymbol{x}_{k}\right), \boldsymbol{Q}_{k, j}\right) \\
&=\arg \min \left(\left(\boldsymbol{z}_{k, j}-h\left(\boldsymbol{x}_{k}, \boldsymbol{y}_{j}\right)\right)^{\mathrm{T}} \boldsymbol{Q}_{k, j}^{-1}\left(\boldsymbol{z}_{k, j}-h\left(\boldsymbol{x}_{k}, \boldsymbol{y}_{j}\right)\right)\right)
\end{aligned} \tag{11}</script><blockquote>
<p>我们发现，该式等价于最小化噪声项的二次型。这个二次型称为马哈拉诺比斯距离，又叫马氏距离。他可以看成由 $\boldsymbol{Q}_{k, j}^{-1}$ 加权之后的欧氏距离，$\boldsymbol{Q}_{k, j}^{-1}$ 称为信息矩阵，即高斯分布协方差矩阵之逆。</p>
</blockquote>
<p>如式（11）所示，我们就是通过找到合适的 $\boldsymbol{x}_k$ 和 $\boldsymbol{y}_j$ ，来使上述值最小。</p>
<p>同样，我们考虑<strong>批量时刻</strong>的数据。通常假设各个时刻的输入和观测是相互独立的，这意味着各个输入之间是独立的，各个观测之间是独立的，并且输入和观测也是独立的。于是我们可以对联合分布进行因式分解：</p>
<script type="math/tex; mode=display">
P(\boldsymbol{z}, \boldsymbol{u} \mid \boldsymbol{x}, \boldsymbol{y})=\prod_{k} P\left(\boldsymbol{u}_{k} \mid \boldsymbol{x}_{k-1}, \boldsymbol{x}_{k}\right) \prod_{k, j} P\left(\boldsymbol{z}_{k, j} \mid \boldsymbol{x}_{k}, \boldsymbol{y}_{j}\right)\tag{12}</script><p>这说明我们可以独立的处理各时刻的运动和观测，定义各个时刻的输入和观测数据与模型之间的误差：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\boldsymbol{e}_{\boldsymbol{u}, k} &=\boldsymbol{x}_{k}-f\left(\boldsymbol{x}_{k-1}, \boldsymbol{u}_{k}\right) \\
\boldsymbol{e}_{\boldsymbol{z}, j, k} &=\boldsymbol{z}_{k, j}-h\left(\boldsymbol{x}_{k}, \boldsymbol{y}_{j}\right)
\end{aligned}\tag{13}</script><p>那么最小化所有时刻估计值与真实读数之间的马氏距离，等价于求最大似然估计，负对数将乘积变成求和：</p>
<script type="math/tex; mode=display">
\min J(\boldsymbol{x}, \boldsymbol{y})=\sum_{k} e_{\boldsymbol{u}, k}^{\mathrm{T}} \boldsymbol{R}_{k}^{-1} e_{\boldsymbol{u}, k}+\sum_{k} \sum_{j} e_{\boldsymbol{z}, k, j}^{\mathrm{T}} \boldsymbol{Q}_{k, j}^{-1} \boldsymbol{e}_{\boldsymbol{z}, k, j}\tag{14}</script><p>这样就得到了一个<strong>最小二乘问题</strong>，它等价于状态的最大似然估计。由于噪声的存在，我们把估计的轨迹和地图带入到SLAM的运动和观测方程中，并不会完美的成立，所以我们要对轨迹和地图进行微调，使整体的误差下降一些。当然这个下降也是有限的，一般会达到一个极小值，这就是一个典型的非线性优化的过程。</p>
<p>式（14）可以代表着SLAM中最小二乘问题具有一些特定的结构：</p>
<ul>
<li>尽管优化变量的维度很高（因为有许多的位置点和路标点），但是要注意，每个观测误差都很简单，仅与一两个状态变量有关。例如运动误差仅与 $\boldsymbol{x_{k-1},x_k}$ 有关，观测误差仅与 $\boldsymbol{x_k,y_j}$ 有关，这种关系会让整个问题有一种稀疏的形式。</li>
<li>如果用李代数表示增量，则该问题是无约束的最小二乘问题。</li>
</ul>
<h2 id="III-非线性最小二乘"><a href="#III-非线性最小二乘" class="headerlink" title="III. 非线性最小二乘"></a>III. 非线性最小二乘</h2><p>我们建立好了代价函数，如何来优化呢？本节就来讨论具体的优化方法。</p>
<p>一个简单的最小二乘问题：</p>
<script type="math/tex; mode=display">
\min _{\boldsymbol{x}} F(\boldsymbol{x})=\frac{1}{2}\sum\|f_i(\boldsymbol{x})\|_{2}^{2}\tag{15}</script><p>其中自变量 $\boldsymbol{x} \in \mathbb{R}^{n}$ ，<strong>$|f_i|^2$ 是任意标量非线性函数 $|f_i(x)|^2: \mathbb{R}^{n} \mapsto \mathbb{R}$ ，它描述每一个观测数据 $i$ 与要估计值间的误差。</strong></p>
<blockquote>
<p>对于视觉SLAM中，式（15）对应的公式是式（14），这里$\boldsymbol f_i(\boldsymbol{x})=\boldsymbol{e}$ ，$|f_i(\boldsymbol{x})|_{2}^{2}=\boldsymbol{e}^TR^{-1}{\boldsymbol e}$ ，这里的 $R^{-1}$ 表示信息矩阵。</p>
</blockquote>
<p>如果 $f_i$ 是个数学形式很简单的函数，那么该问题可以用解析形式来求。令目标函数的导数为零，然后求解 $\boldsymbol {x}$ 的最优值，和求解二元函数的极值一样，即：</p>
<script type="math/tex; mode=display">
\frac{\mathrm{d} F}{\mathrm{~d} \boldsymbol{x}}=\mathbf{0}\tag{16}</script><p>解此方程，得到了导数为0的点，它可能是极大值、极小值或鞍点处的值，只需要逐个比较它们的函数大小即可。<strong>当 $f$ 为简单的线性函数，那么这个问题就是简单的线性最小二乘问题。</strong>但如果 $f$ 的形式复杂，使得该方程不能直接求解，此时我们使用<strong>迭代</strong>的方法，从一个初值出发，不断地更新当前的优化变量，使目标函数下降。</p>
<p>具体步骤：</p>
<ol>
<li>给定某个初始值 $\boldsymbol {x}_0$ </li>
<li>对于第 $k$ 次迭代，寻找一个增量 $\Delta\boldsymbol{x}_k$ ，使得 $\sum\left|f_i\left(\boldsymbol{x}_{k}+\Delta \boldsymbol{x}_{k}\right)\right|_{2}^{2}$ 达到极小值</li>
<li>若 $\Delta\boldsymbol{x}_k$ 足够小，则停止</li>
<li>否则，令 $\boldsymbol{x}_{k+1}=\boldsymbol{x}_k+\Delta\boldsymbol{x}_k$ ，然后返回第二步</li>
<li></li>
</ol>
<blockquote>
<p>该方法就是不断寻找让代价函数变小的增量 $\Delta\boldsymbol{x}_k$ ，由于可以对 $f$ 进行线性化，增量的计算将简单很多。当函数下降直到增量非常小的时候，可以认为算法收敛。</p>
</blockquote>
<p><strong>找到增量是一个局部问题，我们只需要关心函数 $f$ 在迭代处的局部性质即可。</strong></p>
<h3 id="1-一阶和二阶梯度法"><a href="#1-一阶和二阶梯度法" class="headerlink" title="1. 一阶和二阶梯度法"></a>1. 一阶和二阶梯度法</h3><h4 id="1-最速下降法（一阶梯度）"><a href="#1-最速下降法（一阶梯度）" class="headerlink" title="(1)最速下降法（一阶梯度）"></a>(1)最速下降法（一阶梯度）</h4><p>现在考虑第 $k$ 次迭代，假设我们在 $\boldsymbol{x}_k$ 处，想要寻找增量$\Delta\boldsymbol{x}_k$ ，<strong>那么最直观的方法就是将代价函数在  $\boldsymbol{x}_k$ 处进行泰勒展开</strong>：</p>
<script type="math/tex; mode=display">
F\left(\boldsymbol{x}_{k}+\Delta \boldsymbol{x}_{k}\right) \approx F\left(\boldsymbol{x}_{k}\right)+\boldsymbol{J}\left(\boldsymbol{x}_{k}\right)^{\mathrm{T}} \Delta \boldsymbol{x}_{k}+\frac{1}{2} \Delta \boldsymbol{x}_{k}^{\mathrm{T}} \boldsymbol{H}\left(\boldsymbol{x}_{k}\right) \Delta \boldsymbol{x}_{k}\tag{17}</script><p>这里的 $\boldsymbol{J}(\boldsymbol{x}_{k})$ 是 $F\left(\boldsymbol{x}_{k}\right)$ 关于 $\boldsymbol{x}$ 的一阶导数，也叫雅可比矩阵（表示梯度），$\boldsymbol{H}\left(\boldsymbol{x}_{k}\right) $ 则是二阶导数，称为海塞矩阵。<strong>如果仅保留一阶梯度</strong>，那么取增量为反向梯度，即可保证函数下降，即：</p>
<script type="math/tex; mode=display">
\Delta \boldsymbol{x}^{*}=-\boldsymbol{J}\left(\boldsymbol{x}_{k}\right)\tag{18}</script><p>现在的 $\Delta \boldsymbol{x}$ 还仅是一个方向，我们还要指定一个步长 $\lambda$ 。这种方法称为<strong>最速下降法</strong>。</p>
<h4 id="2-牛顿法（二阶梯度）"><a href="#2-牛顿法（二阶梯度）" class="headerlink" title="(2)牛顿法（二阶梯度）"></a>(2)牛顿法（二阶梯度）</h4><p>我们每次讨论的都是第 $k$ 次迭代，为了简化，省略下标 $k$ 。 另外我们还可以保留二阶梯度信息，此时的增量方程为：</p>
<script type="math/tex; mode=display">
\Delta \boldsymbol{x}^{*}=\arg \min \left(F(\boldsymbol{x})+\boldsymbol{J}(\boldsymbol{x})^{\mathrm{T}} \Delta \boldsymbol{x}+\frac{1}{2} \Delta \boldsymbol{x}^{\mathrm{T}} \boldsymbol{H} \Delta \boldsymbol{x}\right)\tag{19}</script><p>即找到一个 $\Delta\boldsymbol{x}_k$ ，让泰勒展开后近似的 $F(\boldsymbol{x}_k+\Delta\boldsymbol{x}_k)$ 最小。我们可以令式（19）对 $\Delta\boldsymbol{x}_k$ 求导，并令其为0，得到：</p>
<script type="math/tex; mode=display">
\boldsymbol{J}+\boldsymbol{H} \Delta \boldsymbol{x}=\mathbf{0} \Rightarrow \boldsymbol{H} \Delta \boldsymbol{x}=-\boldsymbol{J}\tag{20}</script><p>求解这个线性方程，即可得到增量 $\Delta\boldsymbol{x}_k$ ，该方法称为牛顿法。</p>
<p><strong>总结：</strong></p>
<p>一阶和二阶梯度方法实际上就是对原代价函数进行泰勒展开，用一个一次或二次的函数近似原函数，然后用近似函数的最小值来猜测原函数的极小值。但这类方法也有一定的问题，一个是最速下降方法过于贪心，容易走出锯齿路线，反而增加了迭代次数。而牛顿法需要计算代价函数的 $H$ 矩阵，这在问题规模较大时非常困难计算出来。</p>
<h3 id="2-高斯牛顿法"><a href="#2-高斯牛顿法" class="headerlink" title="2. 高斯牛顿法"></a>2. 高斯牛顿法</h3><p>为了避免计算 $H$ 矩阵，采用高斯牛顿法。它的思想就是将 $f_i(x)$ 进行一阶泰勒展开：</p>
<script type="math/tex; mode=display">
f_i(\boldsymbol{x}+\Delta \boldsymbol{x}) \approx f_i(\boldsymbol{x})+\boldsymbol{J}_i(\boldsymbol{x})^{\mathrm{T}} \Delta \boldsymbol{x}\tag{21}</script><p>这里的 $J_i(\boldsymbol x)^T$ 为 $f_i(\boldsymbol x)$ 关于 $\boldsymbol x$ 的导数，为 $n\times 1$ 的列向量。</p>
<p><strong>现在的目标是寻找 $\Delta\boldsymbol x$ 使得 $\sum|f_i(\boldsymbol{x}+\Delta \boldsymbol{x})|^{2}$ 达到最小。</strong> 为了找到这个增量，我们知道这个增量可以使线性化后的代价函数最小，所以有：</p>
<script type="math/tex; mode=display">
\Delta \boldsymbol{x}^{*}=\arg \min _{\Delta \boldsymbol{x}} F(\boldsymbol x)=\arg \min _{\Delta \boldsymbol{x}} \frac{1}{2}\sum\left\|f_i(\boldsymbol{x})+\boldsymbol{J}_i(\boldsymbol{x})^{\mathrm{T}} \Delta \boldsymbol{x}\right\|^{2}\tag{22}</script><p>我们使式（22）右边的平方项展开，得到：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{1}{2}\left\|f_i(\boldsymbol{x})+\boldsymbol{J_i}(\boldsymbol{x})^{\mathrm{T}} \Delta \boldsymbol{x}\right\|^{2} &=\frac{1}{2}\left(f_i(\boldsymbol{x})+\boldsymbol{J}_i(\boldsymbol{x})^{\mathrm{T}} \Delta \boldsymbol{x}\right)^{\mathrm{T}}{R}_i^{-1}\left(f_i(\boldsymbol{x})+\boldsymbol{J}_i(\boldsymbol{x})^{\mathrm{T}} \Delta \boldsymbol{x}\right) \\
&=\frac{1}{2}\left(\|f_i(\boldsymbol{x})\|_{2}^{2}+2\boldsymbol{J}_i(\boldsymbol{x})^{\mathrm{T}} \Delta \boldsymbol{x}{R}_i^{-1}f_i(\boldsymbol{x})+\Delta \boldsymbol{x}^{\mathrm{T}} \boldsymbol{J}_i(\boldsymbol{x}) {R}_i^{-1}\boldsymbol{J}_i(\boldsymbol{x})^{\mathrm{T}} \Delta \boldsymbol{x}\right)
\end{aligned}\tag{23}</script><p><strong>注意：</strong> 这里的 $R_i^{-1}$ 为信息矩阵，也就是噪声的协方差矩阵，它在估计前已经确定，和噪声项有关。</p>
<p>令式（23）对 $\Delta\boldsymbol x$ 求导并令其为零：</p>
<script type="math/tex; mode=display">
\sum\left[\boldsymbol{J}_i(\boldsymbol{x})R_i^{-1} f_i(\boldsymbol{x})+\boldsymbol{J}_i(\boldsymbol{x}) R_i^{-1}\boldsymbol{J}_i^{\mathrm{T}}(\boldsymbol{x}) \Delta \boldsymbol{x}\right]=\mathbf{0}\tag{24}</script><p>可以得到如下方程组：</p>
<script type="math/tex; mode=display">
\underbrace{\sum\boldsymbol{J}_i(\boldsymbol{x})R_i^{-1} \boldsymbol{J}_i^{\mathrm{T}}(\boldsymbol{x})}_{\boldsymbol{H}(\boldsymbol{x})} \Delta \boldsymbol{x}=\underbrace{-\sum\boldsymbol{J}_i(\boldsymbol{x})R_i^{-1}f_i(\boldsymbol{x})}_{\boldsymbol{g}(\boldsymbol{x})}\tag{25}</script><p>这个方程是关于变量 $\Delta\boldsymbol x$ 的线性方程组，我们称为<strong>增量方程</strong>，也可以称为高<strong>斯牛顿方程</strong>（Gauss-Newton equation）或<strong>正规方程</strong>（Normal equation）。</p>
<p>式（25）中，把左边的系数部分定义为 $H$ ，右边定义为 $\boldsymbol{g}$ ，则式（25）变为：</p>
<script type="math/tex; mode=display">
\boldsymbol{H} \Delta \boldsymbol{x}=\boldsymbol{g}\tag{26}</script><p><strong>这里把左边记为 $H$ 是有意义的，对比牛顿法可见，高斯牛顿法是用 $\sum\boldsymbol{J}\boldsymbol{J}^{\mathrm{T}}$ 来作为牛顿法中的二阶海塞矩阵的近似。</strong>从而省略了 $H$ 矩阵的计算过程。</p>
<p>那么高斯牛顿法的算法步骤为：</p>
<ol>
<li>给定初始值 $\boldsymbol {x}_0$ </li>
<li>对于第 $k$ 次迭代，求出当前的雅可比矩阵 $J_i(\boldsymbol{x}_k)$ 和误差 $f_i(\boldsymbol{x}_k)$ </li>
<li>求解增量方程 $\boldsymbol{H} \Delta \boldsymbol{x}=\boldsymbol{g}$</li>
<li><p>若 $\Delta\boldsymbol{x}_k$ 足够小，则停止。否则，令 $\boldsymbol{x}_{k+1}=\boldsymbol{x}_k+\Delta\boldsymbol{x}_k$ ，然后返回第二步</p>
<p><strong>注意：</strong></p>
</li>
</ol>
<p>为了求解增量方程，我们需要求解 $H^{-1}$ ，但实际中计算得到的 $\sum \boldsymbol{J}\boldsymbol{J}^{\mathrm{T}}$ 只有半正定性。因此 $\sum \boldsymbol{J}\boldsymbol{J}^{\mathrm{T}}$ 可能为奇异矩阵或者病态的情况，此时增量的稳定性较差，导致算法不收敛。直观地说，原函数在这个点的局部近似不像一个二次函数，更重要的是即使 $H$ 非奇异也非病态，如果求出的步长太大，也会导致我们局部近似不够准确，这样一来我们无法保证它迭代收敛。</p>
<p>在一些算法中，为了保证合适的步长，采用一些其他的方法，例如<strong>线搜索法</strong>，加入了一个步长 $\alpha$ ，在确定了 $\Delta\boldsymbol{x}$ 后，还要找到一个合适的 $\alpha$ 使 $\sum |f_i(x+\alpha \Delta x)|^{2}$ 最小。</p>
<h3 id="3-列文伯格—马夸尔特法"><a href="#3-列文伯格—马夸尔特法" class="headerlink" title="3. 列文伯格—马夸尔特法"></a>3. 列文伯格—马夸尔特法</h3><p>列文伯格—马夸尔特是建立在高斯牛顿法的基础上，该方法也叫作<strong>阻尼牛顿法</strong> ，它的主要思想是，给 $\Delta\boldsymbol{x}$ 添加了一个范围，称为<strong>信赖区间</strong> 。<strong>这个范围定义了在什么情况下二阶近似是有效的。</strong> 在这个区域里，我们认为近似是有效的，除了这个区域，近似可能会出问题。</p>
<p>我们<strong>通过近似模型和实际函数之间的差异来确定区域的范围。</strong>如果差异小，说明近似效果好，我们扩大近似的范围。反之如果差异大，就缩小范围，我们定义了一个指标 $\rho$ 来刻画近似的好坏程度：</p>
<script type="math/tex; mode=display">
\rho=\frac{\sum \left[f_i(\boldsymbol{x}+\Delta \boldsymbol{x})-f_i(\boldsymbol{x})\right]}{\sum\boldsymbol{J}_i(\boldsymbol{x})^{\mathrm{T}} \Delta \boldsymbol{x}}\tag{27}</script><p>$\rho$ 的分子是实际函数下降的值，分母是近似模型下降的值。如果 $\rho$ 接近于1，则近似是好的。<strong>如果 $\rho$ 太小</strong>，则说明实际下降的值远小于近似模型下降的值，则认为近似比较差，<strong>需要缩小范围</strong>。相反，如果 $\rho$ 太大，则说明近似模型下降的少，而实际函数下降的大，这是件好事，所以我们可以放大近似范围。</p>
<p>所以该算法的步骤为：</p>
<ol>
<li><p>给定初始值 $\boldsymbol {x}_0$ ，以及初始优化半径 $µ$ </p>
</li>
<li><p>对于第 $k$ 次迭代，在高斯牛顿法的基础上（先求当前的雅可比矩阵 $J(\boldsymbol{x}_k)$ 和误差 $f(\boldsymbol{x}_k)$ ），加上信赖区域，求解增量：</p>
<script type="math/tex; mode=display">
\min _{\Delta \boldsymbol{x}_{k}} \frac{1}{2}\sum\left\|f_i\left(\boldsymbol{x}_{k}\right)+\boldsymbol{J}_i\left(\boldsymbol{x}_{k}\right)^{\mathrm{T}} \Delta \boldsymbol{x}_{k}\right\|^{2}, \quad \text { s.t. } \quad\left\|\boldsymbol{D} \Delta \boldsymbol{x}_{k}\right\|^{2} \leqslant \mu\tag{28}</script></li>
</ol>
<p>​       这里的 $D$ 是系数矩阵，$µ$ 是信赖区域半径</p>
<ol>
<li>计算 $\rho$</li>
<li>若 $\rho&gt;\frac{3}{4}$, 则设置 $\mu=2 \mu$ </li>
<li>若$\rho&lt;\frac{1}{4}$, 则设置 $\mu=0.5 \mu$</li>
<li>如果 $\rho $ 大于某阈值, 则认为近似可行。令 $x_{k+1}=x_{k}+\Delta x_{k}$</li>
<li>判断算法是否收敛，如不收敛则返回第2步，否则结束</li>
</ol>
<p><strong>注意：</strong></p>
<p>这里近似范围扩大的倍数和阈值都是经验值，可以替换成别的。在式（28）中，我们把增量限制于一个半径为 $µ$ 的球中，带上 $D$ 之后，这个球可以看成一个椭球。列文伯格提出的优化方法中，$D=I$ ，相当于把增量 $\Delta\boldsymbol{x}$ 约束在一个球内；而马夸尔特提出 $D$ 取非负数对角阵，实际中通常用 $J^TJ$ 的对角元素平方根。</p>
<p>在式（28）中，我们要求解一个带不等式约束的优化问题，我们用拉格朗日乘子把约束项放到代价函数中，构成拉格朗日函数：</p>
<script type="math/tex; mode=display">
\mathcal{L}\left(\Delta \boldsymbol{x}_{k}, \lambda\right)=\frac{1}{2}\sum\left\|f_i\left(\boldsymbol{x}_{k}\right)+\boldsymbol{J}_i\left(\boldsymbol{x}_{k}\right)^{\mathrm{T}} \Delta \boldsymbol{x}_{k}\right\|^{2}+\frac{\lambda}{2}\left(\left\|\boldsymbol{D} \Delta \boldsymbol{x}_{k}\right\|^{2}-\mu\right)\tag{29}</script><p>令式（29）对  $\Delta\boldsymbol{x}$ 求导并等于0，得到：</p>
<script type="math/tex; mode=display">
\left(\boldsymbol{H}+\lambda \boldsymbol{D}^{\mathrm{T}} \boldsymbol{D}\right) \Delta \boldsymbol{x}_{k}=\boldsymbol{g}\tag{30}</script><p>可以看到，相比于高斯牛顿法，增量方程多了一项 $\lambda \boldsymbol{D}^{T} \boldsymbol{D}$ ，如果考虑简化形式，即 $D=I$ ，那么式（30）可以写为：</p>
<script type="math/tex; mode=display">
(\boldsymbol{H}+\lambda \boldsymbol{I}) \Delta \boldsymbol{x}_{k}=\boldsymbol{g}\tag{31}</script><p>我们看到一方面, <strong>当参数 $\lambda$ 比较小时</strong>, $\boldsymbol{H}$ 占主要地位, 这说明二次近似模型在该范围内是比较好的, <strong>列文伯格一马夸尔特方法更接近于高斯牛顿法</strong>。另一方面, <strong>当 $\lambda$ 比较大时</strong>, $\lambda \boldsymbol{I}$ 占据主要地位, <strong>列文伯格一马夸尔特方法更接近于一阶梯度下降法 (即最速下降),</strong> 这说明附近的二次近似不够好。列文伯格一马夸尔特方法的求解方式, 可在一定程度上避免线性方程组的系数矩阵的奇异和病态问题，提供更稳定、更准确的增量 $\Delta \boldsymbol{x}$ 。</p>
<h2 id="IV-总结"><a href="#IV-总结" class="headerlink" title="IV. 总结"></a>IV. 总结</h2><ol>
<li>在批量法求得SLAM中的状态变量时，使用最大似然估计，<strong>该方法最终转化为一个最小二乘问题</strong>。其代价函数是由误差项（包括实际观测值与观测方程计算求得的观测量的差，和实际运动量与运动方程计算出来的运动值的差）和协方差矩阵（观测协方差矩阵和运动协方差矩阵）组成。</li>
<li>在非线性优化时，可以直接将代价函数进行泰勒展开，利用泰勒展开来近似在某一点处的代价函数，从而可以求出增量。但是仅用一阶项（最速下降法）来求会导致算法更加贪心，反复震荡。而考虑二阶项的方法称为牛顿法，需要求海塞矩阵，这是很难求的。</li>
<li>使用高斯牛顿法，就是用 $f$ 函数（注意不是 $F$ 函数）的一阶梯度来近似二阶的海塞矩阵。但是这里要求近似出来的海塞矩阵的逆，这个矩阵是半正定的，所以有时候没有逆，会造成算法失效。而且，即使近似的海塞矩阵有逆，也不能说明近似模型近似的好，有可能效果很差。为了解决这一问题，在高斯牛顿算法的基础上，提出列文伯格—马夸尔特方法。</li>
<li>列文伯格—马夸尔特方法就是在求解增量时，给增量限定在一定的范围内，然后看近似的效果，如果好就放大这个增量的范围。</li>
<li>求解增量的方程是线性方程，我们需要求矩阵的逆来解这个方程，但是由于增量 $\Delta x$ 的维度特别大（通常是成百上千，或是几十万），所以直接求逆是不现实的，我们可以采用矩阵分解的方式（如QR分解，Cholesky分解等）来求解线性方程。</li>
<li>系数矩阵（雅可比矩阵）是稀疏的，这位优化问题提供了可能性。如果是稠密的，视觉SLAM可能就没有发展的必要了。</li>
<li>我们发现，在做优化之前，都需要提供变量的初值，这不是随意给的，一个良好的初值是十分重要的。<strong>不同的初始值可能会有不同的结果。</strong>在视觉SLAM中，我们会用前端算法（如ICP，PnP算法）提供优化的初始值。事实上，这些前端算法也需要优化的方法来求解，然后得到后端优化的初始值，然后再进行优化。</li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/SLAM/" rel="tag"># SLAM</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/07/19/%E3%80%90%E8%A7%86%E8%A7%89SLAM7%E3%80%91%E7%9B%B8%E6%9C%BA%E6%A8%A1%E5%9E%8B/" rel="prev" title="【视觉SLAM7】相机模型">
      <i class="fa fa-chevron-left"></i> 【视觉SLAM7】相机模型
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/07/25/%E3%80%90%E8%A7%86%E8%A7%89SLAM9%E3%80%91Ceres%E5%BA%93/" rel="next" title="【视觉SLAM9】Ceres库">
      【视觉SLAM9】Ceres库 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#I-%E7%8A%B6%E6%80%81%E4%BC%B0%E8%AE%A1%E9%97%AE%E9%A2%98"><span class="nav-text">I. 状态估计问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#II-%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E7%9A%84%E5%BC%95%E5%87%BA"><span class="nav-text">II. 最小二乘的引出</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#III-%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98"><span class="nav-text">III. 非线性最小二乘</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E4%B8%80%E9%98%B6%E5%92%8C%E4%BA%8C%E9%98%B6%E6%A2%AF%E5%BA%A6%E6%B3%95"><span class="nav-text">1. 一阶和二阶梯度法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E6%9C%80%E9%80%9F%E4%B8%8B%E9%99%8D%E6%B3%95%EF%BC%88%E4%B8%80%E9%98%B6%E6%A2%AF%E5%BA%A6%EF%BC%89"><span class="nav-text">(1)最速下降法（一阶梯度）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E7%89%9B%E9%A1%BF%E6%B3%95%EF%BC%88%E4%BA%8C%E9%98%B6%E6%A2%AF%E5%BA%A6%EF%BC%89"><span class="nav-text">(2)牛顿法（二阶梯度）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E9%AB%98%E6%96%AF%E7%89%9B%E9%A1%BF%E6%B3%95"><span class="nav-text">2. 高斯牛顿法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E5%88%97%E6%96%87%E4%BC%AF%E6%A0%BC%E2%80%94%E9%A9%AC%E5%A4%B8%E5%B0%94%E7%89%B9%E6%B3%95"><span class="nav-text">3. 列文伯格—马夸尔特法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#IV-%E6%80%BB%E7%BB%93"><span class="nav-text">IV. 总结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="PiggyHero"
      src="/images/cutexiaoxin.gif">
  <p class="site-author-name" itemprop="name">PiggyHero</p>
  <div class="site-description" itemprop="description">不学习咋整啊！</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">61</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/PiggyHero" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;PiggyHero" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:a363158526@gmail.com" title="E-Mail → mailto:a363158526@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">PiggyHero</span>
</div>

<!--
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>-->


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/canvas_lines.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
